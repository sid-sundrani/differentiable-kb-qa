{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test KBQA model on question pairs\n",
    "* Example notebook to predict get answers to given questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pathlib import Path \n",
    "import sys \n",
    "\n",
    "root_dir = Path(os.getcwd()).parents[0]\n",
    "sys.path.append(str(root_dir))\n",
    "\n",
    "from utils import data_utils\n",
    "from utils.dataset_utils import QADataset\n",
    "import models_nhop\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Paths\n",
    "* Enter your model path and configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = root_dir/'datasets/MetaQA'\n",
    "kg_path = data_dir/'kb.txt'\n",
    "\n",
    "# enter your parameters \n",
    "NUM_HOPS = 1   \n",
    "CKPT_PATH = 'checkpoints\\epoch=0-step=750-v3.ckpt' \n",
    "ENOCDER_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "ENOCDER_SIZE = 384 # hidden size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num entities: 43234\n",
      "num relations: 18\n",
      "num triplets  269482\n",
      "checkpoint loaded\n"
     ]
    }
   ],
   "source": [
    "# create kb matrices\n",
    "triplets, entity_to_idx, relation_to_idx, idx_to_entity, idx_to_relation = data_utils.load_triplets_metaqa(kg_path)\n",
    "\n",
    "subject_matrix, rel_matrix, object_matrix = data_utils.create_differentiable_kg(triplets, entity_to_idx, relation_to_idx)\n",
    "object_matrix = torch.transpose(object_matrix, 0, 1)\n",
    "\n",
    "# load models \n",
    "tokenizer = AutoTokenizer.from_pretrained(ENOCDER_NAME)\n",
    "trans_model = AutoModel.from_pretrained(ENOCDER_NAME)\n",
    "\n",
    "net = models_nhop.KBLightning(trans_model, subject_matrix, rel_matrix, object_matrix, NUM_HOPS, trans_output_size=ENOCDER_SIZE)\n",
    "net = net.load_from_checkpoint(CKPT_PATH, trans_model=trans_model, subject_matrix=subject_matrix, rel_matrix=rel_matrix, object_matrix=object_matrix, num_hops=NUM_HOPS, trans_output_size=ENOCDER_SIZE)\n",
    "print('checkpoint loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on any question\n",
    "* Update eval_pairs with your own questions\n",
    "* The below questions are all onehop questions, since that's the model being tested here. Can utilize two hop model and test those question pairs\n",
    "\n",
    "Key Points:\n",
    "* For practical use-cases, this model has to be trained on un-answerable questions. For example look the 3rd question below. It queries movies acted in, rather it should return no answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of entities missing 0: []\n"
     ]
    }
   ],
   "source": [
    "# create question pair dataset \n",
    "# format: [(question string, answer entities: tuple, subject entity: tuple)]\n",
    "# if you dont have the answer entities, just enter any entity in this from the KB, its not used by the model \n",
    "eval_pairs = [\n",
    "    (\"Ruggero Raimondi appears in what films\", [\"Carmen\"], [\"Ruggero Raimondi\"]),\n",
    "    ('what does Laura Harring act in', ['Mulholland Drive', 'Derailed'], ['Laura Harring']),\n",
    "    ('Which country does Laura Harring live in', ['Mulholland Drive'], ['Laura Harring']), # unanswerable question from KB\n",
    "]\n",
    "\n",
    "# all entities have to be in the KB\n",
    "missing_entities = data_utils.santity_check(eval_pairs, entity_to_idx)\n",
    "\n",
    "if missing_entities:\n",
    "    raise ValueError(f'All entities have to be in the KB. There are {len(missing_entities)} entities in the questions missing: {missing_entities}')\n",
    "\n",
    "# create dataset \n",
    "eval_tokens = tokenizer([row[0] for row in eval_pairs], padding=True, truncation=True, max_length=200, return_tensors='pt')\n",
    "eval_dataset = QADataset(eval_pairs, eval_tokens, entity_to_idx)\n",
    "eval_dl = DataLoader(eval_dataset, batch_size=16)\n",
    "\n",
    "idx_to_entity = {idx: entity for entity, idx in entity_to_idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted answers [['Carmen'], ['Mulholland Drive', 'Derailed'], ['Mulholland Drive', 'Derailed']]\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.70\n",
    "\n",
    "predictions = []\n",
    "for batch in eval_dl:\n",
    "    trans_input, subject_vector, object_labels = batch\n",
    "    subject_vector2 = torch.transpose(subject_vector, 0, 1)\n",
    "    object_logits = net(trans_input, subject_vector2)\n",
    "\n",
    "    object_names, output_ids = models_nhop.interpret_follow_output(object_logits, idx_to_entity, threshold=threshold)\n",
    "    predictions.extend(object_names)\n",
    "\n",
    "print(\"predicted answers\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 ('gnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e61dea2e490c097c24afb18f2e1d0ff0479e13b0c06757a18e315c3ebe25e70b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
